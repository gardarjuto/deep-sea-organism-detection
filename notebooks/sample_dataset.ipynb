{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea1c9204-c633-4b86-bb3b-7a8893501dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from xml.etree import ElementTree\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageStat\n",
    "from random import shuffle\n",
    "import json\n",
    "from torchvision.transforms import functional\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import torch\n",
    "from skimage.transform import resize\n",
    "import cv2\n",
    "\n",
    "sys.path.append('../detection')\n",
    "from fathomnethelper.json_loader import Taxonomicon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10690247-a856-4bde-ac72-eb551b265572",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_per_class = 40  # Number of images per class\n",
    "save_dest = '../data/sample_imgs2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3921f7a7-1d77-410d-abaa-d7cb107293f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../classes\", \"r\") as f:\n",
    "    classes = json.load(f)\n",
    "    \n",
    "root = '../data'\n",
    "imgs = list(sorted(os.listdir(os.path.join(root, 'images'))))\n",
    "anns = list(sorted(os.listdir(os.path.join(root, 'annotations'))))\n",
    "imgs_and_anns = list(zip(imgs,anns))\n",
    "label_mapping = {cls: i+1 for (i, cls) in enumerate(sorted(classes))}\n",
    "tax = Taxonomicon()\n",
    "\n",
    "shuffle(imgs_and_anns)\n",
    "\n",
    "class_mapping = {}\n",
    "for cls in classes:\n",
    "    if type(classes) == list:\n",
    "        nodes = set(tax.get_subtree_nodes(cls))\n",
    "    elif type(classes) == dict:\n",
    "        nodes = set.union(*[set(tax.get_subtree_nodes(cls2)) for cls2 in classes[cls]])\n",
    "    else:\n",
    "        raise TypeError('Class definition needs to be of type list or dict.')\n",
    "    for node in nodes:\n",
    "        class_mapping[node] = cls\n",
    "\n",
    "imgs_and_boxes = {cls: {} for cls in classes}\n",
    "        \n",
    "for img, ann in imgs_and_anns:\n",
    "    if all([len(imgs_and_boxes[cls]) >= N_per_class for cls in classes]):\n",
    "        break\n",
    "    ann_tree = ElementTree.parse(os.path.join(root, 'annotations', ann))\n",
    "    tree_root = ann_tree.getroot()\n",
    "    for box in tree_root.iter('object'):\n",
    "        name = box.find('name').text\n",
    "        if name in class_mapping:\n",
    "            cls = class_mapping[name]\n",
    "            xmin = int(box.find('bndbox/xmin').text)\n",
    "            ymin = int(box.find('bndbox/ymin').text)\n",
    "            xmax = int(box.find('bndbox/xmax').text)\n",
    "            ymax = int(box.find('bndbox/ymax').text)\n",
    "            if img in imgs_and_boxes[cls]:\n",
    "                imgs_and_boxes[cls][img].append((cls, name, (xmin, ymin, xmax, ymax)))\n",
    "            else:\n",
    "                imgs_and_boxes[cls][img] = [(cls, name, (xmin, ymin, xmax, ymax))]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f92311d2-6826-4257-baef-5908988e892a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = 256\n",
    "\n",
    "if not os.path.exists(save_dest):\n",
    "    os.mkdir(save_dest)\n",
    "for cls in classes:\n",
    "    os.mkdir(os.path.join(save_dest, cls))\n",
    "    for img, boxes in list(imgs_and_boxes[cls].items())[:N_per_class]:\n",
    "        im = cv2.imread(os.path.join(root, 'images', img))\n",
    "        # im = Image.open(os.path.join(root, 'images', img)).convert('RGB')\n",
    "        h, w = im.shape[:2]\n",
    "        scalar = 1\n",
    "        if h < min_size or w < min_size:\n",
    "            scalar = min_size / min(h,w)\n",
    "            new_h, new_w = int(h * scalar), int(w * scalar)\n",
    "\n",
    "            im = cv2.resize(im, (new_h, new_w), interpolation = cv2.INTER_AREA)\n",
    "        parent_classes, specific_classes, boxes = zip(*boxes)\n",
    "        colours = [\"white\" if pc == cls else \"grey\" for pc in parent_classes]\n",
    "        labels = [f\"Class={pc}\" for pc, sc in zip(parent_classes, specific_classes)]\n",
    "        # boxes = torch.tensor(boxes)\n",
    "        # res = draw_bounding_boxes(im_tensor, boxes, labels, colours, width=2, font='/home/gardar/.fonts/tamzen-font/ttf/Tamzen10x20b.ttf', font_size=14)\n",
    "        #im = functional.to_pil_image(res)\n",
    "        for (xmin, ymin, xmax, ymax) in boxes:\n",
    "            im = cv2.rectangle(im, (int(xmin*scalar), int(scalar*ymin)), (int(scalar*xmax), int(scalar*ymax)), color=(255, 255, 255), thickness=2)\n",
    "        cv2.imwrite(os.path.join(save_dest, cls, img), im) \n",
    "        \n",
    "        # plt.savefig(os.path.join(save_dest, cls, img), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3961a22b-372c-4d0c-9f2d-71811d949ae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc985c5e-4682-4408-b908-2d31563580e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(486, 720, 3, 486, 720, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e4d381-635d-4975-93fd-211f78782031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
